{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.7.7', ray_version='1.13.0', ray_commit='e4ce38d001dbbe09cd21c497fedd03d692b2be3e', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-06-28_16-56-41_611945_16268/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-06-28_16-56-41_611945_16268/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-06-28_16-56-41_611945_16268', 'metrics_export_port': 65314, 'gcs_address': '127.0.0.1:63030', 'address': '127.0.0.1:63030', 'node_id': 'a1aca497ebb65fe83c57a14af4e112b4d5132452318f8a6abed85631'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "# Other Ray APIs will not work until `ray.init()` is called.\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@PublicAPI\n",
      "@client_mode_hook(auto_init=False)\n",
      "def init(\n",
      "    address: Optional[str] = None,\n",
      "    *,\n",
      "    num_cpus: Optional[int] = None,\n",
      "    num_gpus: Optional[int] = None,\n",
      "    resources: Optional[Dict[str, float]] = None,\n",
      "    object_store_memory: Optional[int] = None,\n",
      "    local_mode: bool = False,\n",
      "    ignore_reinit_error: bool = False,\n",
      "    include_dashboard: Optional[bool] = None,\n",
      "    dashboard_host: str = ray_constants.DEFAULT_DASHBOARD_IP,\n",
      "    dashboard_port: Optional[int] = None,\n",
      "    job_config: \"ray.job_config.JobConfig\" = None,\n",
      "    configure_logging: bool = True,\n",
      "    logging_level: int = ray_constants.LOGGER_LEVEL,\n",
      "    logging_format: str = ray_constants.LOGGER_FORMAT,\n",
      "    log_to_driver: bool = True,\n",
      "    namespace: Optional[str] = None,\n",
      "    runtime_env: Optional[Union[Dict[str, Any], \"RuntimeEnv\"]] = None,  # noqa: F821\n",
      "    storage: Optional[str] = None,\n",
      "    # The following are unstable parameters and their use is discouraged.\n",
      "    _enable_object_reconstruction: bool = False,\n",
      "    _redis_max_memory: Optional[int] = None,\n",
      "    _plasma_directory: Optional[str] = None,\n",
      "    _node_ip_address: str = ray_constants.NODE_DEFAULT_IP,\n",
      "    _driver_object_store_memory: Optional[int] = None,\n",
      "    _memory: Optional[int] = None,\n",
      "    _redis_password: str = ray_constants.REDIS_DEFAULT_PASSWORD,\n",
      "    _temp_dir: Optional[str] = None,\n",
      "    _metrics_export_port: Optional[int] = None,\n",
      "    _system_config: Optional[Dict[str, str]] = None,\n",
      "    _tracing_startup_hook: Optional[Callable] = None,\n",
      "    _node_name: str = None,\n",
      "    **kwargs,\n",
      ") -> BaseContext:\n",
      "    \"\"\"\n",
      "    Connect to an existing Ray cluster or start one and connect to it.\n",
      "\n",
      "    This method handles two cases; either a Ray cluster already exists and we\n",
      "    just attach this driver to it or we start all of the processes associated\n",
      "    with a Ray cluster and attach to the newly started cluster.\n",
      "\n",
      "    To start Ray locally and all of the relevant processes, use this as\n",
      "    follows:\n",
      "\n",
      "    .. code-block:: python\n",
      "\n",
      "        ray.init()\n",
      "\n",
      "    To connect to an existing local cluster, use this as follows.\n",
      "\n",
      "    .. code-block:: python\n",
      "\n",
      "        ray.init(address=\"auto\")\n",
      "\n",
      "    To connect to an existing remote cluster, use this as follows (substituting\n",
      "    in the appropriate address). Note the addition of \"ray://\" at the beginning\n",
      "    of the address.\n",
      "\n",
      "    .. code-block:: python\n",
      "\n",
      "        ray.init(address=\"ray://123.45.67.89:10001\")\n",
      "\n",
      "    More details for starting and connecting to a remote cluster can be found\n",
      "    here: https://docs.ray.io/en/master/cluster/ray-client.html\n",
      "\n",
      "    You can also define an environment variable called `RAY_ADDRESS` in\n",
      "    the same format as the `address` parameter to connect to an existing\n",
      "    cluster with ray.init() or ray.init(address=\"auto\").\n",
      "\n",
      "    Args:\n",
      "        address (str): The address of the Ray cluster to connect to. If\n",
      "            this address is not provided, then this command will start Redis,\n",
      "            a raylet, a plasma store, a plasma manager, and some workers.\n",
      "            It will also kill these processes when Python exits. If the driver\n",
      "            is running on a node in a Ray cluster, using `auto` as the value\n",
      "            tells the driver to detect the cluster, removing the need to\n",
      "            specify a specific node address. If the environment variable\n",
      "            `RAY_ADDRESS` is defined and the address is None or \"auto\", Ray\n",
      "            will set `address` to `RAY_ADDRESS`.\n",
      "            Addresses can be prefixed with a \"ray://\" to connect to a remote\n",
      "            cluster. For example, passing in the address\n",
      "            \"ray://123.45.67.89:50005\" will connect to the cluster at the\n",
      "            given address.\n",
      "        num_cpus (int): Number of CPUs the user wishes to assign to each\n",
      "            raylet. By default, this is set based on virtual cores.\n",
      "        num_gpus (int): Number of GPUs the user wishes to assign to each\n",
      "            raylet. By default, this is set based on detected GPUs.\n",
      "        resources: A dictionary mapping the names of custom resources to the\n",
      "            quantities for them available.\n",
      "        object_store_memory: The amount of memory (in bytes) to start the\n",
      "            object store with. By default, this is automatically set based on\n",
      "            available system memory.\n",
      "        local_mode (bool): If true, the code will be executed serially. This\n",
      "            is useful for debugging.\n",
      "        ignore_reinit_error: If true, Ray suppresses errors from calling\n",
      "            ray.init() a second time. Ray won't be restarted.\n",
      "        include_dashboard: Boolean flag indicating whether or not to start the\n",
      "            Ray dashboard, which displays the status of the Ray\n",
      "            cluster. If this argument is None, then the UI will be started if\n",
      "            the relevant dependencies are present.\n",
      "        dashboard_host: The host to bind the dashboard server to. Can either be\n",
      "            localhost (127.0.0.1) or 0.0.0.0 (available from all interfaces).\n",
      "            By default, this is set to localhost to prevent access from\n",
      "            external machines.\n",
      "        dashboard_port(int, None): The port to bind the dashboard server to.\n",
      "            Defaults to 8265 and Ray will automatically find a free port if\n",
      "            8265 is not available.\n",
      "        job_config (ray.job_config.JobConfig): The job configuration.\n",
      "        configure_logging: True (default) if configuration of logging is\n",
      "            allowed here. Otherwise, the user may want to configure it\n",
      "            separately.\n",
      "        logging_level: Logging level, defaults to logging.INFO. Ignored unless\n",
      "            \"configure_logging\" is true.\n",
      "        logging_format: Logging format, defaults to string containing a\n",
      "            timestamp, filename, line number, and message. See the source file\n",
      "            ray_constants.py for details. Ignored unless \"configure_logging\"\n",
      "            is true.\n",
      "        log_to_driver: If true, the output from all of the worker\n",
      "            processes on all nodes will be directed to the driver.\n",
      "        namespace: Namespace to use\n",
      "        runtime_env: The runtime environment to use\n",
      "            for this job (see :ref:`runtime-environments` for details).\n",
      "        storage: [Experimental] Specify a URI for persistent cluster-wide storage.\n",
      "            This storage path must be accessible by all nodes of the cluster, otherwise\n",
      "            an error will be raised. This option can also be specified as the\n",
      "            RAY_STORAGE env var.\n",
      "        _enable_object_reconstruction (bool): If True, when an object stored in\n",
      "            the distributed plasma store is lost due to node failure, Ray will\n",
      "            attempt to reconstruct the object by re-executing the task that\n",
      "            created the object. Arguments to the task will be recursively\n",
      "            reconstructed. If False, then ray.ObjectLostError will be\n",
      "            thrown.\n",
      "        _redis_max_memory: Redis max memory.\n",
      "        _plasma_directory: Override the plasma mmap file directory.\n",
      "        _node_ip_address (str): The IP address of the node that we are on.\n",
      "        _driver_object_store_memory (int): Deprecated.\n",
      "        _memory: Amount of reservable memory resource to create.\n",
      "        _redis_password (str): Prevents external clients without the password\n",
      "            from connecting to Redis if provided.\n",
      "        _temp_dir (str): If provided, specifies the root temporary\n",
      "            directory for the Ray process. Defaults to an OS-specific\n",
      "            conventional location, e.g., \"/tmp/ray\".\n",
      "        _metrics_export_port(int): Port number Ray exposes system metrics\n",
      "            through a Prometheus endpoint. It is currently under active\n",
      "            development, and the API is subject to change.\n",
      "        _system_config (dict): Configuration for overriding\n",
      "            RayConfig defaults. For testing purposes ONLY.\n",
      "        _tracing_startup_hook (str): If provided, turns on and sets up tracing\n",
      "            for Ray. Must be the name of a function that takes no arguments and\n",
      "            sets up a Tracer Provider, Remote Span Processors, and\n",
      "            (optional) additional instruments. See more at\n",
      "            docs.ray.io/tracing.html. It is currently under active development,\n",
      "            and the API is subject to change.\n",
      "        _node_name (str): User-provided node name or identifier. Defaults to\n",
      "            the node IP address.\n",
      "\n",
      "    Returns:\n",
      "        If the provided address includes a protocol, for example by prepending\n",
      "        \"ray://\" to the address to get \"ray://1.2.3.4:10001\", then a\n",
      "        ClientContext is returned with information such as settings, server\n",
      "        versions for ray and python, and the dashboard_url. Otherwise,\n",
      "        a RayContext is returned with ray and python versions, and address\n",
      "        information about the started processes.\n",
      "\n",
      "    Raises:\n",
      "        Exception: An exception is raised if an inappropriate combination of\n",
      "            arguments is passed in.\n",
      "    \"\"\"\n",
      "\n",
      "    # If available, use RAY_ADDRESS to override if the address was left\n",
      "    # unspecified, or set to \"auto\" in the call to init\n",
      "    address_env_var = os.environ.get(ray_constants.RAY_ADDRESS_ENVIRONMENT_VARIABLE)\n",
      "    if address_env_var:\n",
      "        if address is None or address == \"auto\":\n",
      "            address = address_env_var\n",
      "            logger.info(\n",
      "                f\"Using address {address_env_var} set in the environment \"\n",
      "                f\"variable {ray_constants.RAY_ADDRESS_ENVIRONMENT_VARIABLE}\"\n",
      "            )\n",
      "\n",
      "    if address is not None and \"://\" in address:\n",
      "        # Address specified a protocol, use ray client\n",
      "        builder = ray.client(address, _deprecation_warn_enabled=False)\n",
      "\n",
      "        # Forward any keyword arguments that were changed from their default\n",
      "        # values to the builder\n",
      "        init_sig = inspect.signature(init)\n",
      "        passed_kwargs = {}\n",
      "        for argument_name, param_obj in init_sig.parameters.items():\n",
      "            if argument_name in {\"kwargs\", \"address\"}:\n",
      "                # kwargs and address are handled separately\n",
      "                continue\n",
      "            default_value = param_obj.default\n",
      "            passed_value = locals()[argument_name]\n",
      "            if passed_value != default_value:\n",
      "                # passed value is different than default, pass to the client\n",
      "                # builder\n",
      "                passed_kwargs[argument_name] = passed_value\n",
      "        passed_kwargs.update(kwargs)\n",
      "        builder._init_args(**passed_kwargs)\n",
      "        return builder.connect()\n",
      "\n",
      "    if kwargs:\n",
      "        # User passed in extra keyword arguments but isn't connecting through\n",
      "        # ray client. Raise an error, since most likely a typo in keyword\n",
      "        unknown = \", \".join(kwargs)\n",
      "        raise RuntimeError(f\"Unknown keyword argument(s): {unknown}\")\n",
      "\n",
      "    # Try to increase the file descriptor limit, which is too low by\n",
      "    # default for Ray: https://github.com/ray-project/ray/issues/11239\n",
      "    try:\n",
      "        import resource\n",
      "\n",
      "        soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
      "        if soft < hard:\n",
      "            # https://github.com/ray-project/ray/issues/12059\n",
      "            soft = max(soft, min(hard, 65536))\n",
      "            logger.debug(\n",
      "                f\"Automatically increasing RLIMIT_NOFILE to max value of {hard}\"\n",
      "            )\n",
      "            try:\n",
      "                resource.setrlimit(resource.RLIMIT_NOFILE, (soft, hard))\n",
      "            except ValueError:\n",
      "                logger.debug(\"Failed to raise limit.\")\n",
      "        soft, _ = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
      "        if soft < 4096:\n",
      "            logger.warning(\n",
      "                \"File descriptor limit {} is too low for production \"\n",
      "                \"servers and may result in connection errors. \"\n",
      "                \"At least 8192 is recommended. --- \"\n",
      "                \"Fix with 'ulimit -n 8192'\".format(soft)\n",
      "            )\n",
      "    except ImportError:\n",
      "        logger.debug(\"Could not import resource module (on Windows)\")\n",
      "        pass\n",
      "\n",
      "    if ray_constants.RAY_RUNTIME_ENV_HOOK in os.environ:\n",
      "        runtime_env = _load_class(os.environ[ray_constants.RAY_RUNTIME_ENV_HOOK])(\n",
      "            runtime_env\n",
      "        )\n",
      "\n",
      "    if RAY_JOB_CONFIG_JSON_ENV_VAR in os.environ:\n",
      "        if runtime_env:\n",
      "            logger.warning(\n",
      "                \"Both RAY_JOB_CONFIG_JSON_ENV_VAR and ray.init(runtime_env) \"\n",
      "                \"are provided, only using JSON_ENV_VAR to construct \"\n",
      "                \"job_config. Please ensure no runtime_env is used in driver \"\n",
      "                \"script's ray.init() when using job submission API.\"\n",
      "            )\n",
      "        # Set runtime_env in job_config if passed as env variable, such as\n",
      "        # ray job submission with driver script executed in subprocess\n",
      "        job_config_json = json.loads(os.environ.get(RAY_JOB_CONFIG_JSON_ENV_VAR))\n",
      "        job_config = ray.job_config.JobConfig.from_json(job_config_json)\n",
      "    # RAY_JOB_CONFIG_JSON_ENV_VAR is only set at ray job manager level and has\n",
      "    # higher priority in case user also provided runtime_env for ray.init()\n",
      "    elif runtime_env:\n",
      "        # Set runtime_env in job_config if passed in as part of ray.init()\n",
      "        if job_config is None:\n",
      "            job_config = ray.job_config.JobConfig()\n",
      "        job_config.set_runtime_env(runtime_env)\n",
      "\n",
      "    if _node_ip_address is not None:\n",
      "        node_ip_address = services.resolve_ip_for_localhost(_node_ip_address)\n",
      "    raylet_ip_address = node_ip_address\n",
      "\n",
      "    bootstrap_address, redis_address, gcs_address = None, None, None\n",
      "    if address:\n",
      "        bootstrap_address = services.canonicalize_bootstrap_address(address)\n",
      "        assert bootstrap_address is not None\n",
      "        logger.info(\n",
      "            f\"Connecting to existing Ray cluster at address: {bootstrap_address}\"\n",
      "        )\n",
      "        gcs_address = bootstrap_address\n",
      "\n",
      "    if configure_logging:\n",
      "        setup_logger(logging_level, logging_format)\n",
      "\n",
      "    if local_mode:\n",
      "        driver_mode = LOCAL_MODE\n",
      "    else:\n",
      "        driver_mode = SCRIPT_MODE\n",
      "\n",
      "    global _global_node\n",
      "\n",
      "    if global_worker.connected:\n",
      "        if ignore_reinit_error:\n",
      "            logger.info(\"Calling ray.init() again after it has already been called.\")\n",
      "            node_id = global_worker.core_worker.get_current_node_id()\n",
      "            return RayContext(dict(_global_node.address_info, node_id=node_id.hex()))\n",
      "        else:\n",
      "            raise RuntimeError(\n",
      "                \"Maybe you called ray.init twice by accident? \"\n",
      "                \"This error can be suppressed by passing in \"\n",
      "                \"'ignore_reinit_error=True' or by calling \"\n",
      "                \"'ray.shutdown()' prior to 'ray.init()'.\"\n",
      "            )\n",
      "\n",
      "    _system_config = _system_config or {}\n",
      "    if not isinstance(_system_config, dict):\n",
      "        raise TypeError(\"The _system_config must be a dict.\")\n",
      "\n",
      "    if bootstrap_address is None:\n",
      "        # In this case, we need to start a new cluster.\n",
      "\n",
      "        # Don't collect usage stats in ray.init().\n",
      "        from ray._private.usage import usage_lib\n",
      "\n",
      "        usage_lib.set_usage_stats_enabled_via_env_var(False)\n",
      "\n",
      "        # Use a random port by not specifying Redis port / GCS server port.\n",
      "        ray_params = ray._private.parameter.RayParams(\n",
      "            node_ip_address=node_ip_address,\n",
      "            raylet_ip_address=raylet_ip_address,\n",
      "            object_ref_seed=None,\n",
      "            driver_mode=driver_mode,\n",
      "            redirect_output=None,\n",
      "            num_cpus=num_cpus,\n",
      "            num_gpus=num_gpus,\n",
      "            resources=resources,\n",
      "            num_redis_shards=None,\n",
      "            redis_max_clients=None,\n",
      "            redis_password=_redis_password,\n",
      "            plasma_directory=_plasma_directory,\n",
      "            huge_pages=None,\n",
      "            include_dashboard=include_dashboard,\n",
      "            dashboard_host=dashboard_host,\n",
      "            dashboard_port=dashboard_port,\n",
      "            memory=_memory,\n",
      "            object_store_memory=object_store_memory,\n",
      "            redis_max_memory=_redis_max_memory,\n",
      "            plasma_store_socket_name=None,\n",
      "            temp_dir=_temp_dir,\n",
      "            storage=storage,\n",
      "            # We need to disable it if runtime env is not set.\n",
      "            # Uploading happens after core worker is created. And we should\n",
      "            # prevent default worker being created before uploading.\n",
      "            # TODO (yic): Have a separate connection to gcs client when\n",
      "            # removal redis is done. The uploading should happen before this\n",
      "            # one.\n",
      "            start_initial_python_workers_for_first_job=(\n",
      "                job_config is None or job_config.runtime_env is None\n",
      "            ),\n",
      "            _system_config=_system_config,\n",
      "            enable_object_reconstruction=_enable_object_reconstruction,\n",
      "            metrics_export_port=_metrics_export_port,\n",
      "            tracing_startup_hook=_tracing_startup_hook,\n",
      "            node_name=_node_name,\n",
      "        )\n",
      "        # Start the Ray processes. We set shutdown_at_exit=False because we\n",
      "        # shutdown the node in the ray.shutdown call that happens in the atexit\n",
      "        # handler. We still spawn a reaper process in case the atexit handler\n",
      "        # isn't called.\n",
      "        _global_node = ray.node.Node(\n",
      "            head=True, shutdown_at_exit=False, spawn_reaper=True, ray_params=ray_params\n",
      "        )\n",
      "    else:\n",
      "        # In this case, we are connecting to an existing cluster.\n",
      "        if num_cpus is not None or num_gpus is not None:\n",
      "            raise ValueError(\n",
      "                \"When connecting to an existing cluster, num_cpus \"\n",
      "                \"and num_gpus must not be provided.\"\n",
      "            )\n",
      "        if resources is not None:\n",
      "            raise ValueError(\n",
      "                \"When connecting to an existing cluster, \"\n",
      "                \"resources must not be provided.\"\n",
      "            )\n",
      "        if object_store_memory is not None:\n",
      "            raise ValueError(\n",
      "                \"When connecting to an existing cluster, \"\n",
      "                \"object_store_memory must not be provided.\"\n",
      "            )\n",
      "        if _system_config is not None and len(_system_config) != 0:\n",
      "            raise ValueError(\n",
      "                \"When connecting to an existing cluster, \"\n",
      "                \"_system_config must not be provided.\"\n",
      "            )\n",
      "        if _enable_object_reconstruction:\n",
      "            raise ValueError(\n",
      "                \"When connecting to an existing cluster, \"\n",
      "                \"_enable_object_reconstruction must not be provided.\"\n",
      "            )\n",
      "        if _node_name is not None:\n",
      "            raise ValueError(\n",
      "                \"_node_name cannot be configured when connecting to \"\n",
      "                \"an existing cluster.\"\n",
      "            )\n",
      "\n",
      "        # In this case, we only need to connect the node.\n",
      "        ray_params = ray._private.parameter.RayParams(\n",
      "            node_ip_address=node_ip_address,\n",
      "            raylet_ip_address=raylet_ip_address,\n",
      "            gcs_address=gcs_address,\n",
      "            redis_address=redis_address,\n",
      "            redis_password=_redis_password,\n",
      "            object_ref_seed=None,\n",
      "            storage=storage,\n",
      "            temp_dir=_temp_dir,\n",
      "            _system_config=_system_config,\n",
      "            enable_object_reconstruction=_enable_object_reconstruction,\n",
      "            metrics_export_port=_metrics_export_port,\n",
      "        )\n",
      "        _global_node = ray.node.Node(\n",
      "            ray_params,\n",
      "            head=False,\n",
      "            shutdown_at_exit=False,\n",
      "            spawn_reaper=False,\n",
      "            connect_only=True,\n",
      "        )\n",
      "\n",
      "    connect(\n",
      "        _global_node,\n",
      "        mode=driver_mode,\n",
      "        log_to_driver=log_to_driver,\n",
      "        worker=global_worker,\n",
      "        driver_object_store_memory=_driver_object_store_memory,\n",
      "        job_id=None,\n",
      "        namespace=namespace,\n",
      "        job_config=job_config,\n",
      "    )\n",
      "    if job_config and job_config.code_search_path:\n",
      "        global_worker.set_load_code_from_local(True)\n",
      "    else:\n",
      "        # Because `ray.shutdown()` doesn't reset this flag, for multiple\n",
      "        # sessions in one process, the 2nd `ray.init()` will reuse the\n",
      "        # flag of last session. For example:\n",
      "        #     ray.init(load_code_from_local=True)\n",
      "        #     ray.shutdown()\n",
      "        #     ray.init()\n",
      "        #     # Here the flag `load_code_from_local` is still True if we\n",
      "        #     # doesn't have this `else` branch.\n",
      "        #     ray.shutdown()\n",
      "        global_worker.set_load_code_from_local(False)\n",
      "\n",
      "    for hook in _post_init_hooks:\n",
      "        hook()\n",
      "\n",
      "    node_id = global_worker.core_worker.get_current_node_id()\n",
      "    return RayContext(dict(_global_node.address_info, node_id=node_id.hex()))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(ray.init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/bankde/opt/anaconda3/envs/ml/lib/python3.7/site-packages/ray/_private/client_mode_hook.py'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getsourcefile(ray.init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
